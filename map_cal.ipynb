{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [--weights WEIGHTS [WEIGHTS ...]]\n",
      "                             [--source SOURCE] [--data DATA]\n",
      "                             [--imgsz IMGSZ [IMGSZ ...]]\n",
      "                             [--conf-thres CONF_THRES] [--iou-thres IOU_THRES]\n",
      "                             [--max-det MAX_DET] [--device DEVICE]\n",
      "                             [--view-img] [--save-txt] [--save-conf]\n",
      "                             [--save-crop] [--nosave]\n",
      "                             [--classes CLASSES [CLASSES ...]]\n",
      "                             [--agnostic-nms] [--augment] [--visualize]\n",
      "                             [--update] [--project PROJECT] [--name NAME]\n",
      "                             [--exist-ok] [--line-thickness LINE_THICKNESS]\n",
      "                             [--hide-labels] [--hide-conf] [--half] [--dnn]\n",
      "                             [--vid-stride VID_STRIDE]\n",
      "ipykernel_launcher.py: error: unrecognized arguments: --ip=127.0.0.1 --stdin=9021 --control=9019 --hb=9018 --Session.signature_scheme=\"hmac-sha256\" --Session.key=b\"c1b51cf9-c0b5-4b7a-ae5c-9b3363995b4c\" --shell=9020 --transport=\"tcp\" --iopub=9022 --f=/home/imu/.local/share/jupyter/runtime/kernel-v2-28842jEtdrmmuLDf7.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "import detect_mod\n",
    "from pprint import pprint\n",
    "\n",
    "detection_config = vars(detect_mod.parse_opt())\n",
    "\n",
    "detection_model = detect_mod.warmup_model(weights=detection_config['weights'],\n",
    "                                            data=detection_config['data'])\n",
    "for key in ['weights', 'data', 'imgsz', 'device', 'half', 'dnn', 'source']:\n",
    "    detection_config.pop(key)\n",
    "\n",
    "def load_data(image_dir, label_dir):\n",
    "    # Sorted list of image and label files\n",
    "    image_files = sorted(os.listdir(image_dir))\n",
    "    label_files = sorted(os.listdir(label_dir))\n",
    "\n",
    "    images = []\n",
    "    targets = []\n",
    "\n",
    "    for image_file, label_file in zip(image_files, label_files):\n",
    "        # Ensure corresponding pairs\n",
    "        assert image_file.split('/')[-1][:-4] == label_file.split('/')[-1][:-4]\n",
    "\n",
    "        # Load image\n",
    "        image = Image.open(os.path.join(image_dir, image_file))\n",
    "        image_width, image_height = image.size\n",
    "        # image = torch.Tensor(image)  # Convert to tensor\n",
    "        images.append(image)\n",
    "\n",
    "        # Load labels\n",
    "        with open(os.path.join(label_dir, label_file), 'r') as f:\n",
    "            labels = f.readlines()\n",
    "            boxes = []\n",
    "            classes = []\n",
    "            for label in labels:\n",
    "                cls, x, y, w, h = map(float, label.split())\n",
    "                # Convert normalized coordinates to original size\n",
    "                x = x * image_width\n",
    "                y = y * image_height\n",
    "                w = w * image_width\n",
    "                h = h * image_height\n",
    "                # Convert to x1, y1, x2, y2 format\n",
    "                x1 = x - w / 2\n",
    "                y1 = y - h / 2\n",
    "                x2 = x + w / 2\n",
    "                y2 = y + h / 2\n",
    "                boxes.append([x1, y1, x2, y2])\n",
    "                classes.append(int(cls))\n",
    "\n",
    "            targets.append({\n",
    "                    \"boxes\": torch.tensor(boxes),\n",
    "                    \"labels\": torch.tensor(classes)\n",
    "                })\n",
    "    \n",
    "    return images, targets\n",
    "\n",
    "# Load your data\n",
    "images, targets = load_data(\"./runs/experiment/original/image/\", \"./runs/experiment/original/label/\")\n",
    "# detections = detect_mod.run_detection(detection_model, images, **detection_config)\n",
    "# pprint(detections)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 7\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mdetect_mod\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mpprint\u001b[39;00m \u001b[39mimport\u001b[39;00m pprint\n\u001b[0;32m----> 7\u001b[0m detection_config \u001b[39m=\u001b[39m \u001b[39mvars\u001b[39m(detect_mod\u001b[39m.\u001b[39;49mparse_opt())\n\u001b[1;32m      9\u001b[0m detection_model \u001b[39m=\u001b[39m detect_mod\u001b[39m.\u001b[39mwarmup_model(weights\u001b[39m=\u001b[39mdetection_config[\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m],\n\u001b[1;32m     10\u001b[0m                                             data\u001b[39m=\u001b[39mdetection_config[\u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     11\u001b[0m \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m [\u001b[39m'\u001b[39m\u001b[39mweights\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdata\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mimgsz\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdevice\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mhalf\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mdnn\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39msource\u001b[39m\u001b[39m'\u001b[39m]:\n",
      "File \u001b[0;32m~/work/cv_ml_project/latest/yolo5-pytorch/detect_mod.py:188\u001b[0m, in \u001b[0;36mparse_opt\u001b[0;34m()\u001b[0m\n\u001b[1;32m    186\u001b[0m parser\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39m--dnn\u001b[39m\u001b[39m'\u001b[39m, action\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstore_true\u001b[39m\u001b[39m'\u001b[39m, help\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39muse OpenCV DNN for ONNX inference\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    187\u001b[0m parser\u001b[39m.\u001b[39madd_argument(\u001b[39m'\u001b[39m\u001b[39m--vid-stride\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mtype\u001b[39m\u001b[39m=\u001b[39m\u001b[39mint\u001b[39m, default\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m, help\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvideo frame-rate stride\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 188\u001b[0m opt \u001b[39m=\u001b[39m parser\u001b[39m.\u001b[39;49mparse_args()\n\u001b[1;32m    189\u001b[0m opt\u001b[39m.\u001b[39mimgsz \u001b[39m*\u001b[39m\u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(opt\u001b[39m.\u001b[39mimgsz) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m1\u001b[39m  \u001b[39m# expand\u001b[39;00m\n\u001b[1;32m    190\u001b[0m print_args(\u001b[39mvars\u001b[39m(opt))\n",
      "File \u001b[0;32m~/anaconda3/envs/yolo5/lib/python3.10/argparse.py:1829\u001b[0m, in \u001b[0;36mArgumentParser.parse_args\u001b[0;34m(self, args, namespace)\u001b[0m\n\u001b[1;32m   1827\u001b[0m \u001b[39mif\u001b[39;00m argv:\n\u001b[1;32m   1828\u001b[0m     msg \u001b[39m=\u001b[39m _(\u001b[39m'\u001b[39m\u001b[39munrecognized arguments: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m-> 1829\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49merror(msg \u001b[39m%\u001b[39;49m \u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m.\u001b[39;49mjoin(argv))\n\u001b[1;32m   1830\u001b[0m \u001b[39mreturn\u001b[39;00m args\n",
      "File \u001b[0;32m~/anaconda3/envs/yolo5/lib/python3.10/argparse.py:2583\u001b[0m, in \u001b[0;36mArgumentParser.error\u001b[0;34m(self, message)\u001b[0m\n\u001b[1;32m   2581\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprint_usage(_sys\u001b[39m.\u001b[39mstderr)\n\u001b[1;32m   2582\u001b[0m args \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mprog\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprog, \u001b[39m'\u001b[39m\u001b[39mmessage\u001b[39m\u001b[39m'\u001b[39m: message}\n\u001b[0;32m-> 2583\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexit(\u001b[39m2\u001b[39;49m, _(\u001b[39m'\u001b[39;49m\u001b[39m%(prog)s\u001b[39;49;00m\u001b[39m: error: \u001b[39;49m\u001b[39m%(message)s\u001b[39;49;00m\u001b[39m\\n\u001b[39;49;00m\u001b[39m'\u001b[39;49m) \u001b[39m%\u001b[39;49m args)\n",
      "File \u001b[0;32m~/anaconda3/envs/yolo5/lib/python3.10/argparse.py:2570\u001b[0m, in \u001b[0;36mArgumentParser.exit\u001b[0;34m(self, status, message)\u001b[0m\n\u001b[1;32m   2568\u001b[0m \u001b[39mif\u001b[39;00m message:\n\u001b[1;32m   2569\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_print_message(message, _sys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m-> 2570\u001b[0m _sys\u001b[39m.\u001b[39;49mexit(status)\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2"
     ]
    }
   ],
   "source": [
    "%tb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "yolo5",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
